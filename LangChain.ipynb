{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84434598",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39eae9c",
   "metadata": {},
   "source": [
    "LangChain is a framework for developing applications powered by language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed3f24",
   "metadata": {},
   "source": [
    "Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee47741",
   "metadata": {},
   "source": [
    "Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03755a05",
   "metadata": {},
   "source": [
    "Components for Working with Language Models:\n",
    "LangChain provides a set of building blocks (components) that you can use to work with language models. These components are like tools that help you interact with language models more easily. Imagine them as Lego pieces that you can put together to create something.\n",
    "\n",
    "Example: Think of a language model as a robot that can answer questions. LangChain's components would be like different parts of the robot, such as arms, legs, and a brain. You can assemble these parts to make the robot do various tasks like answering questions or having conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a7805",
   "metadata": {},
   "source": [
    "Off-the-Shelf Chains for Specific Tasks:\n",
    "LangChain offers pre-designed sets of components (chains) that are ready to use for specific tasks. These pre-built chains are like ready-made solutions for common language-related tasks. They save you time and effort because you don't need to build everything from scratch.\n",
    "\n",
    "Example: Imagine you want to create a chatbot that can book hotel rooms. LangChain provides a pre-made \"Hotel Booking Chatbot Chain\" that includes all the necessary components (parts) like understanding user messages, searching for hotels, and making reservations. You can simply use this chain without starting from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c684d",
   "metadata": {},
   "source": [
    "Customization and Building New Chains:\n",
    "If you have more complex or unique tasks, LangChain allows you to customize the existing chains or build entirely new ones. This means you can tailor the pre-made chains to suit your specific needs or create entirely new solutions from the available components.\n",
    "\n",
    "Example: Let's say you have a unique language-related task like translating ancient texts. You can take the components from LangChain, like language understanding and translation, and put them together in a new way to create a specialized \"Ancient Text Translator Chain.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0240b75",
   "metadata": {},
   "source": [
    "In summary, LangChain is a framework that offers easy-to-use tools (components) for working with language models. It also provides pre-made solutions (chains) for common tasks, making it simple to get started. However, you can also customize these solutions or build your own for more complex or unique language-related projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88d24aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to install LangChain..?\n",
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0eb0e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need another package called openai\n",
    "#pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036be671",
   "metadata": {},
   "source": [
    "LangChain provides many modules that can be used to build language model applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3674feff",
   "metadata": {},
   "source": [
    "The most common and most important chain that LangChain helps create contains three things:\n",
    "\n",
    "LLM: The language model is the core reasoning engine here. In order to work with LangChain, you need to understand the different types of language models and how to work with them.\n",
    "\n",
    "Prompt Templates: This provides instructions to the language model. This controls what the language model outputs, so understanding how to construct prompts and different prompting strategies is crucial.\n",
    "\n",
    "Output Parsers: These translate the raw response from the LLM to a more workable format, making it easy to use the output downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51256c3",
   "metadata": {},
   "source": [
    "# LLM\n",
    "\n",
    "There are two types of language models, which in LangChain are called:\n",
    "\n",
    "LLMs: this is a language model which takes a string as input and returns a string\n",
    "\n",
    "ChatModels: this is a language model which takes a list of messages as input and returns a message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e20108",
   "metadata": {},
   "source": [
    "content: This is the content of the message.\n",
    "    \n",
    "role: This is the role of the entity from which the ChatMessage is coming from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e834b",
   "metadata": {},
   "source": [
    "predict: Takes in a string, returns a string\n",
    "    \n",
    "predict_messages: Takes in a list of messages, returns a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c326420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21d59db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Api key:..........."
     ]
    }
   ],
   "source": [
    "openai_api_key = input(\"Enter Your Api key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5403e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=openai_api_key,temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12530d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\hi!\");\\n    var2.startAllNodeStep(0);\\n    var2.startAbsoluteLocationPath();\\n    var2.startXPath();\\n    var2.endAllNodeStep();\\n    var2.endFilterExpr();\\n    \\n    // Regression assertion (captures the current behavior of the code)\\n    assertTrue(var5 == false);\\n\\n  }\\n\\n  public void test378() throws Throwable {\\n\\n    if (debug) System.out.printf(\"%nRandoopTest13.test378\");\\n\\n\\n    org.saxpath.helpers.DefaultXPathHandler var0 = new org.saxpath.helpers.DefaultXPathHandler();\\n    var0.number(10.0d);\\n    var0.endPathExpr();\\n    var0.endUnionExpr(false);\\n    var0.endEqualityExpr(1);\\n    var0.endXPath();\\n    var0.startProcessingInstructionNodeStep(100, \"(0) startAbsoluteLocationPath()\\\\n(1) endAndExpr(true)\\\\n\");\\n    var0.endOrEx'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee3945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "chat_model = ChatOpenAI(openai_api_key=openai_api_key, temperature = 0.7)\n",
    "\n",
    "response = chat_model.predict(\"hi!\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f53f7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nAir.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"what is that things that has no colour that are very usefull on the earth for leaving organisms?\"\n",
    "\n",
    "llm.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7499e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One thing that is colorless but very useful for living organisms on Earth is water. Water is essential for various biological processes. It is the main constituent of cells and tissues in all living organisms, helping to maintain their structure and function. Water is also involved in nutrient transport, waste removal, temperature regulation, and lubrication of joints. Additionally, water supports ecosystems by providing habitats for aquatic organisms and facilitating the cycling of nutrients.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "512247ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33f0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "040eb90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n\\nAnswer: Air.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6377ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='One thing that has no color but is extremely useful for living organisms on Earth is air or the atmosphere. Air is a mixture of gases, primarily nitrogen, oxygen, carbon dioxide, and trace amounts of other gases. It is essential for the survival of organisms as it provides oxygen for respiration, allows for the exchange of gases in the lungs, helps regulate temperature, and carries moisture for precipitation.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61843bc8",
   "metadata": {},
   "source": [
    "# Prompt Template:\n",
    "Most LLM applications do not pass user input directly into an LLM. Usually they will add the user input to a larger piece of text, called a prompt template, that provides additional context on the specific task at hand.\n",
    "\n",
    "In the previous example, the text we passed to the model contained instructions to generate a company name. For our application, it'd be great if the user only had to provide the description of a company/product, without having to worry about giving the model instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "406f4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06209d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e2c155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what is that things that has no colour that are very usefull on the earth for leaving organisms? that was in the form of Liquid?'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1 = PromptTemplate.from_template(\"what is that things that has no colour that are very usefull on the earth for leaving organisms? that was in the form of {product}?\")\n",
    "prompt1.format(product=\"Liquid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63514829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3291addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are the helpfull assistent that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}.\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad518c3b",
   "metadata": {},
   "source": [
    "template = {\"role\": \"system\", \"content\": \"You are the helpful assistant that translates {input_language} to {output_language}.\"}\n",
    "\n",
    "human_template = {\"role\": \"user\", \"content\": \"{text}.\"}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff5a0902",
   "metadata": {},
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    template,\n",
    "    human_template,\n",
    "])\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61687e0e",
   "metadata": {},
   "source": [
    "formatted_messages = chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")\n",
    "print(formatted_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d25f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "templete = template.format(input_language=\"English\", output_language=\"French\")\n",
    "\n",
    "human_template = human_template.format(text = \"I love programming !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbba0569",
   "metadata": {},
   "source": [
    "# Output parsers\n",
    "OutputParsers convert the raw output of an LLM into a format that can be used downstream. There are few main type of OutputParsers, including:\n",
    "\n",
    "1) Convert text from LLM -> structured information (e.g. JSON)\n",
    "\n",
    "2) Convert a ChatMessage into just a string\n",
    "\n",
    "3) Convert the extra information returned from a call besides the message (like OpenAI function invocation) into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d1f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d16ceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94dd8ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21776b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
